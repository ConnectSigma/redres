---
title: "redres: Redress Your Mixed Model Assumptions"
author: "R Package Version `r packageVersion('redres')`"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

The Merriam-Webster dictionary defines [redress](https://www.merriam-webster.com/dictionary/redress) as "to set right".

# Package Functions 

Section describing what each function does, how to use the function, and how to interpret the plots...

## redres

## plot_resid

## plot_genres

## plot_raneff

## Quantile plots

Quantile plots are used to verify visually if data follows are particular distribution. Data points are plotted along the quantiles of the assumed distributed. The data is expected to follow an approximately straight line, at least along the middle quantiles. The points are assessed for any extreme curvation that would indicate a departure from the assumed distribution. Typically curvature at the extreme ends of the quantiles (around 0 and 1) are ignored as data is sparse here and distributions behave more erratically at the boundaries of the parameter space. We have added confidence bands to guide the user.  

The function `plot_ranef` plots each random effect vector along the normal quantiles. From the assumptions of the linear mixed model, each random effect specified - along with the error term - is assumed to follow a normal distribution. Therefore, these plots can be used to assess if this assumption is met. Note that the number of plots generated by this function will vary for each model, with the number of plots being the number of random effects.  

To assess all model assumptions together, the user can view the generalized residual plot called by `plot_genres`. If the specified model is reasonable for the data, then the generalized residuals should follow an independent sample from a continuous $Uniform(0,1)$.  Thus, by plotting the generalized residuals against the quantiles of a uniform distribution, the user can detect obvious departures from the model. The details of how the generalized residuals are calculated is below. (include hyperlink?)

## shiny app function

# Residual Types

Section on how to compute the different residual types and when to use them...

The linear mixed effects model can be written as
  $$\textbf{Y}=\textbf{X}\boldsymbol{\beta}+\textbf{Z}\boldsymbol{\gamma}+\boldsymbol{\epsilon}$$
where

- $\textbf{Y}$ is an $n\times 1$ vector of $n$ response variable observations,
- $\textbf{X}$ is an $n\times p$ matrix of $p$ explanatory variables with $n$ observations each,
- $\boldsymbol{\beta}$ is a $p\times1$ vector of unknown fixed effects parameters,
- $\textbf{Z}$ is an $n\times q$ matrix of $q$ random effect variables with $n$ observations each,
- $\boldsymbol{\gamma}$ is a $q\times1$ vector of unknown random effects, and
- $\boldsymbol{\epsilon}$ is an $n\times1$ vector of random errors.

By assumption, it is the case that...
$$ 
\begin{bmatrix} \boldsymbol{\gamma} \\ \boldsymbol{\epsilon} \end{bmatrix}
  \sim N 
    \begin{pmatrix} 
      \begin{bmatrix} \boldsymbol{0} \\ \boldsymbol{0} \end{bmatrix},
      \begin{bmatrix} \textbf{G} & \boldsymbol{0} \\ \boldsymbol{0} & \textbf{R} \end{bmatrix}
    \end{pmatrix}
$$

## Raw

- marginal: 
  $$\textbf{r}^m_i = Y_i-\textbf{x}'_i\hat{\boldsymbol{\beta}}$$
- conditional:
  $$\textbf{r}^c_i = Y_i-\textbf{x}'_i\hat{\boldsymbol{\beta}}-\textbf{z}'_i\hat{\boldsymbol{\gamma}}$$

## Pearson

- marginal: 
  $$\textbf{r}^{m,pearson}_{i} = \frac{r^m_i}{\sqrt{\hat{Var[Y_i]}}}$$
- conditional: 
  $$\textbf{r}^{c,pearson}_{i} = \frac{r^m_i}{\sqrt{\hat{Var[Y_i|\boldsymbol{\gamma}]}}}$$

## Studentized

- marginal:
- conditional:

## lmer residuals

- `type = response, scaled = "FALSE``: $Y-X\hat{\beta}$
- `type = "pearson", scaled = "FALSE`: $(Y-X\hat{\beta}) / w_i$ where $w_i$ is the user specified weights (set to 1 if not specified)
- `type = "pearson", scaled = "TRUE`: $(Y-X\hat{\beta}) / \sigma$

## Generalized
For linear mixed models, we assume that for $i = 1, \ldots, n$, that 
$$ E(Y_i) = \textbf{X}\boldsymbol{\beta} $$
and $$ Var(Y_i) = \textbf{Z}\textbf{G}\textbf{Z}^{T} + \textbf{R}$$

Seems like we would not have independent observations if we fit an AR(1) model or CS... Is this even an option in lmer?

# Example





